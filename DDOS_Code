#Kafka Producer Using Python

import json
from pyspark.sql import types as spark_type
from pyspark.sql import SparkSession # this will help me run this code as a program

schema_string = """
{"fields":[
        {"metadata":{},"name":"ip","nullable":true,"type":"string"},
        {"metadata":{},"name":"_c1","nullable":true,"type":"string"},
        {"metadata":{},"name":"_c2","nullable":true,"type":"string"},
        {"metadata":{},"name":"Time","nullable":true,"type":"string"},
        {"metadata":{},"name":"Time_Zone","nullable":true,"type":"string"},
        {"metadata":{},"name":"Request","nullable":true,"type":"string"},
        {"metadata":{},"name":"Status","nullable":true,"type":"string"},
        {"metadata":{},"name":"Size","nullable":true,"type":"string"},
        {"metadata":{},"name":"Referer","nullable":true,"type":"string"},
        {"metadata":{},"name":"User_Agent","nullable":true,"type":"string"}
],"type":"struct"}
"""
schema = spark_type.StructType.fromJson(json.loads(schema_string))

spark = SparkSession.builder.appName("phdata_producer").getOrCreate() # initalizing spark

df = spark.read.csv("/phdata/apache-access-log.txt",sep=" ", schema=schema)\
    .select("ip","Time","Time_Zone","Request","Status","Size","Referer","User_Agent")

def generate_json_payload_from_columns(row):
        payload = {}
        for f in row.__fields__:
            payload[f] = row[f]
        return payload

df_json = spark.createDataFrame(df.rdd.map(lambda x: {"value": json.dumps(generate_json_payload_from_columns(x))}))

df_json.write.format("kafka") \
    .option("kafka.bootstrap.servers", "sandbox-hdp.hortonworks.com:9092") \
    .option("topic", "phdata9") \
    .save()



#Kafka Consumer 1


import json
from pyspark.sql import functions as spark_func
from pyspark.sql import types as spark_type
from pyspark.sql.functions import length
from pyspark.sql.functions import col

schema_string = """
{"fields":[
        {"metadata":{},"name":"ip","nullable":true,"type":"string"},
        {"metadata":{},"name":"Time","nullable":true,"type":"string"},
        {"metadata":{},"name":"Time_Zone","nullable":true,"type":"string"},
        {"metadata":{},"name":"Request","nullable":true,"type":"string"},
        {"metadata":{},"name":"Status","nullable":true,"type":"string"},
        {"metadata":{},"name":"Size","nullable":true,"type":"string"},
        {"metadata":{},"name":"Referer","nullable":true,"type":"string"},
        {"metadata":{},"name":"User_Agent","nullable":true,"type":"string"}
],"type":"struct"}
"""
schema = spark_type.StructType.fromJson(json.loads(schema_string))


#Read json file from broker topic phdata8
df = spark \
    .readStream \
    .format("kafka") \
    .option("kafka.bootstrap.servers", "sandbox-hdp.hortonworks.com:9092") \
    .option("subscribe", "phdata9") \
    .option("startingOffsets", "earliest")\
    .load()
    
# Print the value in the json file
df_string = df.selectExpr("cast(value as string) as message")

#apply Schema to message
df_struct = df_string.select(spark_func.from_json("message",schema).alias("ms"))


#change feature label 
df_select = df_struct.selectExpr("ms.ip as ip","ms.Time as Time","ms.Time_Zone as Time_Zone",
              "ms.Request as Request","ms.Status as Status","ms.Size as Size",
              "ms.Referer as Referer","ms.User_Agent as User_agent")

df_final = df_select.where(length(col("User_agent")) <30)

df_stream = df_final.writeStream \
    .format("json") \
    .option("path", "/tmp/result") \
    .option("checkpointLocation", "/tmp/checkpoint") \
    .outputMode("Append") \
    .trigger(processingTime='2 seconds') \
    .start()
    
df_stream.awaitTermination()
